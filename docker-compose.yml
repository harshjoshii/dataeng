version: '3.8'
services:
  mysql:
    image: mysql:5
    ports: 
      - "8085:3306"
    container_name: mysql
    environment: 
      - MYSQL_ROOT_PASSWORD=root@123
      - MYSQL_DATABASE=airflow
      - MYSQL_USER=airflow
      - MYSQL_PASSWORD=airflow
    volumes:  
      - mysql:/var/lib/mysql
  
  airflow-init:
    image: apache/airflow
    container_name: airflow-init
    command: initdb
    volumes: 
      - dataeng:/opt/airflow
  
  airflow-scheduler:
    image: apache/airflow
    container_name: airflow-scheduler
    command: scheduler
    depends_on: 
      - airflow-init
    volumes: 
      - dataeng:/opt/airflow

  airflow-webserver:
    image: apache/airflow
    ports:
      - "8080:8080"
    container_name: airflow-webserver
    command: webserver
    depends_on: 
      - airflow-init
    volumes: 
      - dataeng:/opt/airflow

volumes: 
  mysql:
  dataeng:
    external: true

  # spark-master:
  #   image: bde2020/spark-master:3.0.0-hadoop3.2
  #   container_name: spark-master
  #   ports:
  #     - "8082:8080"
  #     - "7077:7077"
  #   environment:
  #     - INIT_DAEMON_STEP=setup_spark
  #     - "constraint:node==spark-master"
  # spark-30.worker-1:
  #   image: bde2020/spark-worker:3.0.0-hadoop3.2
  #   container_name: spark-worker-1
  #   depends_on:
  #     - spark-master
  #   ports:
  #     - "8083:8081"
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"
  #     - "constraint:node==spark-worker-1"
  # spark-worker-2:
  #   image: bde2020/spark-worker:3.0.0-hadoop3.2
  #   container_name: spark-worker-2
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - "SPARK_MASTER=spark://spark-master:7077"
  #     - "constraint:node==spark-worker-2"  