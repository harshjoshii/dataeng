version: '3.8'
services:
  mysql:
    build: 
      context: ./mysql
    image: harshjoshi211/mysql
    ports: 
      - "3306:3306"
    container_name: mysql
    command: --explicit_defaults_for_timestamp=1 --default-authentication-plugin=mysql_native_password
    environment: 
      - MYSQL_ROOT_PASSWORD=root123
      - MYSQL_DATABASE=airflow_mdb
      - MYSQL_USER=airflow
      - MYSQL_PASSWORD=airflow
    volumes:  
      - mysql:/var/lib/mysql
      - shared_volume:/shared_volume    
    healthcheck:
      test: "/usr/bin/mysql --user=root --password=root123 --execute \"SHOW DATABASES;\""
      interval: 10s
      timeout: 50s
      retries: 5
    networks: 
      - dataeng

  airflow-webserver:
    build: 
      context: ./airflow
    image: harshjoshi211/airflow
    ports:
      - "8080:8080"
    container_name: airflow-webserver
    command: webserver
    depends_on: 
      - mysql
    volumes: 
      - airflow:/opt/airflow
      - shared_volume:/shared_volume
    networks: 
      - dataeng
  
  airflow-scheduler:
    build: 
      context: ./airflow
    image: harshjoshi211/airflow
    container_name: airflow-scheduler
    command: scheduler
    depends_on: 
      - airflow-webserver
    volumes: 
      - airflow:/opt/airflow
      - shared_volume:/shared_volume 
    networks: 
      - dataeng

  spark-master:
    image: bde2020/spark-master:3.0.0-hadoop3.2
    container_name: spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - "constraint:node==spark-master"
    networks: 
      - dataeng

  spark-worker-1:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==spark-worker-1"
    networks: 
      - dataeng

  spark-worker-2:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==spark-worker-2"  
    networks: 
      - dataeng

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=dataeng
    env_file:
      - ./hadoop.env
    networks: 
      - dataeng

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    networks: 
      - dataeng
  
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    ports: 
      - 8088:8088
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
    networks: 
      - dataeng

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    ports: 
      - 8042:8042
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    networks: 
      - dataeng
  
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    ports: 
      - 8188:8188
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    networks: 
      - dataeng

volumes: 
  mysql:
    external: true
  airflow:
    external: true
  shared_volume:
    external: true
  hadoop_namenode:
    external: true
  hadoop_datanode:
    external: true
  hadoop_historyserver:
    external: true

networks: 
  dataeng:
    external: true